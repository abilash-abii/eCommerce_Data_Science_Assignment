{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Quantity  TotalValue  \\\n",
      "0      C0001        12     3354.52   \n",
      "1      C0002        10     1862.74   \n",
      "2      C0003        14     2725.38   \n",
      "3      C0004        23     5354.88   \n",
      "4      C0005         7     2034.24   \n",
      "\n",
      "                                          ProductID  \n",
      "0                    [P054, P022, P096, P083, P029]  \n",
      "1                          [P095, P004, P019, P071]  \n",
      "2                          [P025, P006, P035, P002]  \n",
      "3  [P049, P053, P038, P025, P097, P024, P008, P077]  \n",
      "4                                [P025, P039, P012]  \n",
      "Lookalike recommendations saved to 'Abilash_K S_Lookalike.csv'.\n",
      "  CustomerID LookalikeID  SimilarityScore\n",
      "0      C0001       C0107         0.989475\n",
      "1      C0001       C0137         0.987899\n",
      "2      C0001       C0184         0.987695\n",
      "3      C0002       C0088         0.996018\n",
      "4      C0002       C0142         0.987820\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Lookalike Model for eCommerce Transactions Dataset\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the datasets\n",
    "# Customers, Products, and Transactions datasets are loaded into separate DataFrames\n",
    "customers = pd.read_csv(\"Customers.csv\")\n",
    "products = pd.read_csv(\"Products.csv\")\n",
    "transactions = pd.read_csv(\"Transactions.csv\")\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Merging the datasets to create a comprehensive dataset for analysis\n",
    "merged_data = transactions.merge(customers, on=\"CustomerID\").merge(products, on=\"ProductID\")\n",
    "\n",
    "# Aggregating transaction data for each customer\n",
    "customer_transactions = merged_data.groupby(\"CustomerID\").agg({\n",
    "    \"Quantity\": \"sum\",\n",
    "    \"TotalValue\": \"sum\",\n",
    "    \"ProductID\": lambda x: list(x.unique())  # List of unique products purchased\n",
    "}).reset_index()\n",
    "print(customer_transactions.head())\n",
    "\n",
    "# Ensuring customer_transactions matches the length of customers by merging with the customer DataFrame\n",
    "customer_transactions = customers.merge(customer_transactions, on=\"CustomerID\", how=\"left\").fillna(0)\n",
    "\n",
    "# Step 3: One-Hot Encoding the Region column\n",
    "# Encoding categorical data in the Region column\n",
    "encoder = OneHotEncoder()\n",
    "region_encoded = encoder.fit_transform(customers[[\"Region\"]]).toarray()\n",
    "\n",
    "# Creating a DataFrame for encoded Region data\n",
    "region_encoded_df = pd.DataFrame(region_encoded, columns=encoder.get_feature_names_out([\"Region\"]))\n",
    "\n",
    "# Combining customer features with encoded Region and aggregated transaction data\n",
    "customer_features = pd.concat([\n",
    "    customers[\"CustomerID\"],\n",
    "    region_encoded_df,\n",
    "    customer_transactions[[\"Quantity\", \"TotalValue\"]]\n",
    "], axis=1).fillna(0)\n",
    "\n",
    "# Step 4: Standardizing Numerical Features\n",
    "# Standardizing Quantity and TotalValue for better similarity calculations\n",
    "scaler = StandardScaler()\n",
    "numerical_features = [\"Quantity\", \"TotalValue\"]\n",
    "customer_features[numerical_features] = scaler.fit_transform(customer_features[numerical_features])\n",
    "\n",
    "# Step 5: Calculating Cosine Similarity\n",
    "# Setting CustomerID as the index and calculating similarity between customers\n",
    "customer_features.set_index(\"CustomerID\", inplace=True)\n",
    "similarity_matrix = cosine_similarity(customer_features)\n",
    "\n",
    "# Step 6: Generating Recommendations for the First 20 Customers\n",
    "# Recommending top 3 lookalike customers for the first 20 customers\n",
    "lookalike_recommendations = {}\n",
    "customer_ids = customers[\"CustomerID\"].tolist()\n",
    "\n",
    "for idx, customer_id in enumerate(customer_ids[:20]):  # Processing the first 20 customers\n",
    "    # Getting similarity scores for the current customer\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    # Sorting scores to find the top 3 most similar customers (excluding the customer itself)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:4]\n",
    "    \n",
    "    # Mapping Customer IDs to their similarity scores\n",
    "    lookalike_recommendations[customer_id] = [\n",
    "        (customer_ids[score[0]], score[1]) for score in similarity_scores\n",
    "    ]\n",
    "\n",
    "# Step 7: Saving Recommendations to a CSV File\n",
    "# Converting recommendations into a DataFrame for saving and further analysis\n",
    "lookalike_data = []\n",
    "for cust_id, recommendations in lookalike_recommendations.items():\n",
    "    for rec in recommendations:\n",
    "        lookalike_data.append([cust_id, rec[0], rec[1]])\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=[\"CustomerID\", \"LookalikeID\", \"SimilarityScore\"])\n",
    "lookalike_df.to_csv(\"Lookalike.csv\", index=False)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Lookalike recommendations saved to 'Abilash_K S_Lookalike.csv'.\")\n",
    "print(lookalike_df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
